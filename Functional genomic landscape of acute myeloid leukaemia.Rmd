---
title: "Functional genomic landscape of acute myeloid leukaemia"
author: "Inês Lameira (PG40080), João Lima (PG55701), Romeu Fernandes (PG45861)"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    css: styles.css
  pdf_document:
    citation_package: biblatex
bibliography: references.bib
csl: nature.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Definindo um repositório CRAN
options(repos = c(CRAN = "https://cran.rstudio.com"))
```

Trabalho desenvolvido no âmbito da unidade curricular de Extração de Conhecimento de Dados Biológicos (2024/2025), referente ao Mestrado em Bioinformática da Escola de Engenharia da Universidade do Minho. O objetivo deste trabalho é desenvolver scripts em R/ Bioconductor para carregar os dados, préprocessá-los e fazer um conjunto de análises relativas aos datasets de leucemia.

## Packages Utilizados

No desenvolvimento deste trabalho foram vários os packages necessários para realizar as análises que posteriormente serão apresentadas:

```{r}
#instalar os pacotes necessários
#install.packages("ggplot2")
#install.packages("DESeq2")
```

```{r}
# Carregar os pacotes necessários
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(forcats)
library(RColorBrewer)
library(knitr)
```

## Enquadramento

A leucemia mieloide aguda (LMA) é uma doença hematológica agressiva, marcada pela multiplicação descontrolada de precursores mieloides imaturos na medula óssea, levando à interrupção da produção normal de sangue. Esta condição atinge principalmente indivíduos de idade avançada, com uma média de diagnóstico superior a 65 anos [@jemal2010cancer]. Prevê-se que, anualmente, nos Estados Unidos, mais de 20.000 novos casos de LMA sejam identificados, resultando em cerca de 11.000 óbitos anuais [@seer2018aml].

A LMA é extremamente diversificada em termos genéticos, com mutações somáticas em genes como *NPM1*, *FLT3*, *IDH1*, *IDH2*, *DNMT3A*, entre outros, desempenhando um papel prognóstico e até terapêutico [@papaemmanuil2016genomic; @patel2012prognostic]. Pesquisas de sequenciamento em grande escala, como as realizadas pelo The Cancer Genome Atlas (TCGA), possibilitaram a categorização da LMA em diversos subgrupos moleculares com perfis de risco e respostas distintas ao tratamento [@tcga2013aml].

Ainda que tenha havido progressos na terapia, como a implementação de terapias direcionadas contra mutações em FLT3 [@stone2017midostaurin] e IDH1/IDH2 [@rohle2013idh1; @wang2013idh2], a terapia convencional que envolve quimioterapia intensiva manteve-se praticamente inalterada nas últimas quatro décadas [@huang1988retinoic; @shen1997arsenic]. Adicionalmente, mutações no gene TP53 e mudanças epigenéticas associadas, como mutações genéticas em TET2 ou ASXL1, persistem como desafios clínicos devido à sua ligação com resistência ao tratamento [@welch2016tp53; @itzykson2011tet2].

Neste contexto, o projeto **Beat AML** destaca-se como um marco significativo ao combinar dados funcionais e genómicos de um conjunto de 672 amostras tumorais provenientes de 562 pacientes. Estudos de sequenciamento do exoma, sequenciamento de RNA e testes in vivo de sensibilidade a fármacos foram conduzidos, proporcionando uma perspetiva multidimensional da biologia da LMA [@tyner2018functional]. As informações deste estudo estão acessíveis ao público no portal Vizome e representam um recurso valioso para a pesquisa de novos biomarcadores, assinaturas moleculares e possíveis alvos terapêuticos.

Este trabalho, inserido na unidade curricular de **Extração de Conhecimento de Dados Biológicos**, visa empregar técnicas estatísticas e de *data mining* nos dados de expressão genética do *cohort* Beat AML, utilizando R e Bioconductor. As avaliações englobam o pré-processamento e a exploração dos dados, a identificação de genes com expressão diferenciada e a utilização de técnicas de aprendizagem automática para antecipar perfis moleculares e respostas terapêuticas.

## Importação dos datasets

```{r}
# Importação dos datasets
dc_pacientes <- read.table("data_clinical_patient.txt", sep = "\t", header = TRUE)
dc_amostras <- read.table("data_clinical_sample.txt", sep = "\t", header = TRUE, fill = TRUE)
```

# 1. Pacientes

## 1.0. Pré-análise do dataset

```{r, eval=FALSE}
# Análise preliminar do dataset com os dados clínicos dos pacientes
dim(dc_pacientes)
head(dc_pacientes)
names(dc_pacientes)
nrow(dc_pacientes)
ncol(dc_pacientes)
class(dc_pacientes)
unlist(lapply(dc_pacientes, class))
sum(is.na.data.frame(dc_pacientes))
na_por_coluna_pacientes <- colSums(is.na(dc_pacientes)) 
na_por_coluna_pacientes[na_por_coluna_pacientes > 0] 
```

## 1.0.1. Tratamento de valores omissos

```{r}
# Teste de normalidade
teste_normalidade <- shapiro.test(dc_pacientes$AGE_AT_DIAGNOSIS)
teste_normalidade
```

O teste de Shapiro permitiu concluir que a idade não segue uma distribuição normal e portanto os valores omissos foram substituídos pelo mediana.

```{r}
# Substituindo valores omissos pela mediana
mediana_idade <- median(dc_pacientes$AGE_AT_DIAGNOSIS, na.rm = TRUE)
dc_pacientes$AGE_AT_DIAGNOSIS[is.na(dc_pacientes$AGE_AT_DIAGNOSIS)] <- mediana_idade
sum(is.na(dc_pacientes$AGE_AT_DIAGNOSIS)) 
```

## 1.1. Sexo

```{r}
sexo_df <- as.data.frame(table(dc_pacientes$SEX))
colnames(sexo_df) <- c("Sexo", "Contagem")
sexo_df <- sexo_df %>%
  mutate(Percentual = round(Contagem / sum(Contagem) * 100, 1),
         Label = paste0(Sexo, " (", Percentual, "%)"))
cores_sexo <- c("Female" = "#F7A6B9",  
                "Male" = "#8FC1E3")

ggplot(sexo_df, aes(x = "", y = Contagem, fill = Sexo)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  geom_text(aes(label = Label), position = position_stack(vjust = 0.5), color = "black", size = 4.2) +
  scale_fill_manual(values = cores_sexo) +
  labs(title = "Distribuição dos Pacientes por Sexo", x = NULL, y = NULL, fill = "Sexo") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14))
```

## 1.2. Etnia

```{r}
summary(dc_pacientes$ETHNICITY)
etnia_contagens <- table(dc_pacientes$ETHNICITY)
percentagens_etnia <- round(100 * etnia_contagens / sum(etnia_contagens), 1)

etnia_data <- data.frame(
  Etnia = names(etnia_contagens),
  Contagem = as.numeric(etnia_contagens),
  Percentagem = as.numeric(percentagens_etnia)
)
etnia_data <- etnia_data[order(etnia_data$Contagem), ]

cores_etnia <- brewer.pal(n = max(3, min(nrow(etnia_data), 8)), name = "Pastel2")
ggplot(etnia_data, aes(x = Contagem, y = reorder(Etnia, -Contagem), fill = Etnia)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(label = paste0(Percentagem, "%")),
            hjust = -0.8, size = 4.2, color = "black") +  
  scale_fill_manual(values = cores_etnia) +
  scale_y_discrete(expand = expansion(mult = c(0.05, 0.15))) +
  labs(title = "Distribuição das Etnias dos Pacientes",
       x = "Número de Pacientes", y = "Etnia") +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 11),
    axis.text.x = element_text(size = 11),
    axis.title = element_text(size = 13),
    plot.title = element_text(size = 15, hjust = 0.5)
  ) +
  expand_limits(x = max(etnia_data$Contagem) * 1.3) +
  coord_flip()
```

## 1.3. Idade

```{r}
summary(dc_pacientes$AGE_AT_DIAGNOSIS)

ggplot(dc_pacientes, aes(y = AGE_AT_DIAGNOSIS)) +
  geom_boxplot(fill = "#8FC1E3", color = "black", outlier.color = "red", outlier.shape = 16) +
  labs(title = "Boxplot das idades de diagnóstico",
       y = "Idade", x = NULL) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    axis.title.y = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

## 1.4. Diagnóstico

```{r}
summary(dc_pacientes$DIAGNOSIS)
diagnostico_contagens <- table(dc_pacientes$DIAGNOSIS)

diagnostico_contagens <- table(dc_pacientes$DIAGNOSIS)

ggplot(data.frame(Diagnostico = names(diagnostico_contagens), Contagem = as.numeric(diagnostico_contagens)), 
       aes(x = reorder(Diagnostico, -Contagem), y = Contagem)) +
  geom_bar(stat = "identity", fill = "#69b3a2") +
  scale_y_log10() +
  labs(title = "Distribuição do diagnóstico (escala logarítmica)",
       x = "Diagnóstico", y = "Número de Pacientes (log10)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

## 1.5. Tratamento

```{r, echo=FALSE}
tratamento_frequencias <- table(dc_pacientes$TREATMENT_TYPE)
tratamento_frequencias
```
```{r}
kable(as.data.frame(tratamento_frequencias), col.names = c("Tipo de Tratamento", "Frequência"))
threshold_treatmentos <- 20
tratamentos_raros <- names(tratamento_frequencias[tratamento_frequencias < threshold_treatmentos])
```

Para facilitar a visualização gráfica, os tratamentos com menos de 20 ocorrências vão ser somados na variável outros

```{r}
dc_pacientes$TREATMENT_TYPE[dc_pacientes$TREATMENT_TYPE %in% tratamentos_raros] <- "Outros"
dc_pacientes$TREATMENT_TYPE[dc_pacientes$TREATMENT_TYPE == ""] <- "Desconhecido"
tratamento_frequencias_final <- table(dc_pacientes$TREATMENT_TYPE)
tratamento_frequencias_final_ordenado <- sort(tratamento_frequencias_final, decreasing = FALSE)

tratamento_df <- as.data.frame(tratamento_frequencias_final_ordenado)
colnames(tratamento_df) <- c("Tratamento", "Contagem")
ggplot(tratamento_df, aes(x = reorder(Tratamento, -Contagem), y = Contagem, fill = Tratamento)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  coord_flip() +  
  labs(title = "Distribuição dos Tratamentos", 
       x = "Número de Pacientes", 
       y = "Tratamento") +
  scale_fill_brewer(palette = "Set3") +  
  theme_minimal() +
  theme(axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 8),
        plot.title = element_text(hjust = 0.5, face = "bold", size = 14))
```

## 1.6. Estado de sobrevivência

```{r, eval = FALSE}
table(dc_pacientes$OS_STATUS)
sum(dc_pacientes$OS_STATUS == "")
```

Os valores omissos nesta variável vão ser substituídos por estado "desconhecido"

```{r}
dc_pacientes$OS_STATUS[dc_pacientes$OS_STATUS == ""] <- "UNKNOWN"
table(dc_pacientes$OS_STATUS)
estado_contagens <- table(dc_pacientes$OS_STATUS)
```

```{r}
barplot(estado_contagens,
        main = "Distribuição do Estado de Sobrevivência",
        ylab = "Número de Pacientes",
        col = c("khaki3", "tomato3", "lightblue1"),
        border = "white",
        names.arg = c("Vivo", "Morto", "Desconhecido"))
```

# 2. Amostras

## 2.0 Pré-análise do dataset

```{r, eval=FALSE}
dim(dc_amostras)
head(dc_amostras)
names(dc_amostras)
str(dc_amostras)
sum(is.na(dc_amostras))
na_por_coluna_amostras <- colSums(is.na(dc_amostras))
na_por_coluna_amostras[na_por_coluna_amostras > 0]
```

## 2.1. Classificações de risco ELN

```{r, eval=FALSE}
table(dc_amostras$ELN_2017)
table(dc_amostras$ELN_2017, useNA = "ifany")
```

```{r grafico_etnia, fig.width=8, fig.height=1.2 * nrow(etnia_data)}
eln_freq <- table(dc_amostras$ELN_2017)
cores_eln <- c("olivedrab3", "gold", "lightcoral", "skyblue", "plum", "grey40")[1:length(eln_freq)]

barplot(eln_freq,
        main = "Classificação ELN 2017",
        ylab = "Número de Amostras",
        col = cores_eln,
        border = "white",
        las = 2,                         
        cex.names = 0.9,               
        cex.axis = 0.8,                 
        cex.main = 1.2,                 
        ylim = c(0, max(eln_freq) * 1.2)) 
```

## 2.2. Percentagem de blastos na medula

```{r, eval=FALSE}
sum(is.na(dc_amostras$BM_BLAST_PERCENTAGE))
```

### 2.2.1. Teste de normalidade (Shapiro-Wilk)

```{r}
shapiro_result <- shapiro.test(dc_amostras$BM_BLAST_PERCENTAGE[!is.na(dc_amostras$BM_BLAST_PERCENTAGE)])
shapiro_result 
```

Como p\<0.05, os dados não seguem uma distribuição normal, pelo que será utilizada a mediana.

### 2.2.2. Mediana de blastos na medula

```{r}
mediana_blastos <- median(dc_amostras$BM_BLAST_PERCENTAGE, na.rm = TRUE)
dc_amostras$BM_BLAST_PERCENTAGE[is.na(dc_amostras$BM_BLAST_PERCENTAGE)] <- mediana_blastos
```

### 2.2.3. Tabela sumária das estatísticas descritivas

```{r, eval=FALSE}
summary(dc_amostras$BM_BLAST_PERCENTAGE)
```

```{r}
boxplot(dc_amostras$BM_BLAST_PERCENTAGE,
        main = "Percentagem de Blastos na Medula Óssea",
        ylab = "% de Blastos",
        col = "skyblue",
        border = "grey40",
        notch = TRUE,           
        outline = TRUE,         
        frame = FALSE,          
        cex.axis = 0.9,
        cex.main = 1.2)
abline(h = median(dc_amostras$BM_BLAST_PERCENTAGE, na.rm = TRUE), col = "red", lty = 2)
```

## 2.3. Percentagem de blastos no sangue periférico

```{r, eval=FALSE}
sum(is.na(dc_amostras$PB_BLAST_PERCENTAGE))
```

### 2.3.1. Teste de normalidade (Shapiro-Wilk)

```{r}
shapiro_result_pb <- shapiro.test(dc_amostras$PB_BLAST_PERCENTAGE[!is.na(dc_amostras$PB_BLAST_PERCENTAGE)])
shapiro_result_pb
```

Como p\<0.05, os dados não seguem uma distribuição normal pelo que será utilizada a mediana

### 2.3.2. Mediana de blastos no sangue periférico

```{r}
mediana_pb_blastos <- median(dc_amostras$PB_BLAST_PERCENTAGE, na.rm = TRUE)
dc_amostras$PB_BLAST_PERCENTAGE[is.na(dc_amostras$PB_BLAST_PERCENTAGE)] <- mediana_pb_blastos
```

### 2.3.3. Tabela sumária das estatísticas descritivas

```{r,eval=FALSE}
summary(dc_amostras$PB_BLAST_PERCENTAGE)
```

```{r}
boxplot(dc_amostras$PB_BLAST_PERCENTAGE,
        main = "Percentagem de Blastos no Sangue Periférico",
        ylab = "% de Blastos",
        col = "lightcoral",
        border = "grey40",
        notch = TRUE,
        outline = TRUE,
        frame = FALSE,
        cex.axis = 0.9,
        cex.main = 1.2)
abline(h = median(dc_amostras$PB_BLAST_PERCENTAGE, na.rm = TRUE), col = "red", lty = 2)
```

## 2.4. Cariótipo - ocorrências mais frequentes

```{r}
karyo_clean <- dc_amostras$KARYOTYPE[dc_amostras$KARYOTYPE != ""]
karyo_freq <- sort(table(karyo_clean), decreasing = TRUE)
karyo_freq_top <- head(karyo_freq, 10)

cores_gradiente <- colorRampPalette(c("dodgerblue4", "lightblue"))(length(karyo_freq_top))
barplot(karyo_freq_top,
        main = "Principais cariótipos",
        col = cores_gradiente,  
        ylab = "Número de Amostras",
        xlab = "Cariótipo",
        las = 2,  
        cex.names = 0.8, 
        cex.axis = 0.9,  
        cex.main = 1.2,  
        cex.lab = 1.1,   
        border = NA,     
        horiz = FALSE,   
        ylim = c(0, max(karyo_freq_top) + 5),
        xpd = TRUE 
)
```

## 2.5. Resposta à indução

```{r, eval=FALSE}
table(dc_amostras$INDUCTION_RESPONSE)
```

Reclassificação das categorias de modo a juntar todos os valores desconhecidos

```{r, eval=FALSE}
dc_amostras$INDUCTION_RESPONSE <- gsub("(?i)unknown|^\\s*$", "Unknown", dc_amostras$INDUCTION_RESPONSE, perl = TRUE)
```

Filtragem dos dados para excluir os valores "Unknown"

```{r}
induction_response_filtrados <- dc_amostras[dc_amostras$INDUCTION_RESPONSE != "Unknown", ]
table(induction_response_filtrados$INDUCTION_RESPONSE)

response_counts <- table(induction_response_filtrados$INDUCTION_RESPONSE)
pie(response_counts,
    main = "Distribuição da Resposta à Indução",
    col = c("#A8D08D", "#F9E79F", "#F4CCCC"),  # Cores suaves
    labels = paste("\n", response_counts, " casos"),
    border = "white",
    radius = 0.9,
    cex = 1.2)
legend("topright", 
       legend = names(response_counts), 
       fill = c("#A8D08D", "#F9E79F", "#F4CCCC"),  # Cores harmoniosas
       title = "Respostas à Indução",
       title.col = "black",  # Cor do título
       cex = 1,  # Tamanho do texto da legenda
       box.lwd = 1,  # Espessura da borda da legenda
       box.col = "white",  # Cor da borda da legenda
       bg = "transparent")
```

## 2.6. Contagem do número de glóbulos brancos

```{r}
dc_amostras$WBC[dc_amostras$WBC == ""] <- NA
sum(is.na(dc_amostras$WBC))
WBC_clean <- dc_amostras$WBC[dc_amostras$WBC != "" & !is.na(dc_amostras$WBC)]
sum(is.na(WBC_clean))
WBC_clean <- as.numeric(WBC_clean)
```

Verificação de valores que não são numéricos

```{r, eval=FALSE}
non_numeric_values <- WBC_clean[!grepl("^[0-9.]+$", WBC_clean)]
print(non_numeric_values)
WBC_clean <- WBC_clean[grepl("^[0-9.]+$", WBC_clean)]
WBC_clean <- as.numeric(WBC_clean)
sum(is.na(WBC_clean))
summary(WBC_clean)
```

```{r}

boxplot(WBC_clean, 
        main = "Boxplot de WBC", 
        ylab = "Contagem de Leucócitos (WBC)", 
        col = "lightgreen",        
        border = "darkgreen",      
        notch = TRUE,             
        horizontal = FALSE,        
        ylim = c(0, 150),          
        outline = TRUE,            
        whisklty = 1,              
        boxwex = 0.5,              
        notchcol = "darkgreen",    
        main.col = "darkblue",     
        cex.main = 1.5,            
        cex.lab = 1.2)             
abline(h = median(WBC_clean, na.rm = TRUE), col = "red", lwd = 2, lty = 2)
```

## 2.7. Estudo do efeito da resposta à indução no número de glóbulos brancos

```{r}
dc_amostras_limpos <- dc_amostras[!is.na(dc_amostras$WBC) & dc_amostras$WBC != "" &
                                    !is.na(dc_amostras$INDUCTION_RESPONSE) & dc_amostras$INDUCTION_RESPONSE != "", ]
str(WBC_clean)
length(WBC_clean)
length(dc_amostras$INDUCTION_RESPONSE)
head(dc_amostras$WBC)
dc_amostras$WBC_clean <- as.numeric(dc_amostras$WBC)
dc_amostras$WBC_clean[dc_amostras$WBC_clean == ""] <- NA
dados_filtrados <- dc_amostras[!is.na(dc_amostras$WBC_clean) & !is.na(dc_amostras$INDUCTION_RESPONSE), ]
length(dados_filtrados$WBC_clean)
length(dados_filtrados$INDUCTION_RESPONSE)
```

```{r}
boxplot(WBC_clean ~ INDUCTION_RESPONSE, 
        data = dados_filtrados,  
        main = "Distribuição do número de glóbulos brancos por resposta à indução",
        xlab = "Resposta à Indução", 
        ylab = "Contagem de Leucócitos (WBC)",
        col = c("lightblue", "lightgreen", "lightcoral", "lightyellow"),  
        border = "black",
        las = 2,  
        cex.axis = 0.8) 
```

### 2.7.1. Teste de Kruskal-Wallis para comparar WBC entre as categorias de resposta à indução

```{r}
kruskal_test_result <- kruskal.test(WBC_clean ~ INDUCTION_RESPONSE, 
                                    data = dados_filtrados)
print(kruskal_test_result)
```

Como p-value = 0.07914 \> 0.05, não há diferenças significativas nas medianas das contagens de leucócitos entre as diferentes categorias de resposta à indução (ao nível de significância de 5%)

## 2.8. Visualização exploratória das variáveis hematológicas por grupo ELN, após normalizar os dados com z-score

### 2.8.1. Seleção e normalização

```{r}
variaveis_pb_norm <- dc_amostras %>%
  select(ELN_2017, PB_BASOPHILS_PERCENTAGE, PB_BLAST_PERCENTAGE, PB_EOSINOPHILS_PERCENTAGE,
         PB_IMMATURE_GRANULOCYTES_PERCENTAGE, PB_LYMPHOCYTES_PERCENTAGE,
         PB_MONOCYTES_PERCENTAGE, PB_NEUTROPHILS_PERCENTAGE, PB_NUCLEATED_RBC_PERCENTAGE) %>%
  filter(!is.na(ELN_2017)) %>%
  drop_na() %>%
  mutate(across(-ELN_2017, scale)) %>%
  pivot_longer(-ELN_2017, names_to = "Celula", values_to = "Z_score") %>%
  mutate(Celula = case_when(
    Celula == "PB_BASOPHILS_PERCENTAGE" ~ "Basófilos",
    Celula == "PB_BLAST_PERCENTAGE" ~ "Blastos",
    Celula == "PB_EOSINOPHILS_PERCENTAGE" ~ "Eosinófilos",
    Celula == "PB_IMMATURE_GRANULOCYTES_PERCENTAGE" ~ "Granulócitos Imaturos",
    Celula == "PB_LYMPHOCYTES_PERCENTAGE" ~ "Linfócitos",
    Celula == "PB_MONOCYTES_PERCENTAGE" ~ "Monócitos",
    Celula == "PB_NEUTROPHILS_PERCENTAGE" ~ "Neutrófilos",
    Celula == "PB_NUCLEATED_RBC_PERCENTAGE" ~ "Hemácias Nucleadas",
    TRUE ~ Celula
  )) %>%
  mutate(Celula = fct_reorder(Celula, Z_score, .fun = median))
```

### 2.8.2. Análise univariada comparando os valores normalizados de cada célula separadamente, entre grupos ELN, usando boxplots.

```{r}
paleta_eln <- c(
  "Adverse" = "#D73027",               
  "Intermediate" = "#FC8D59",          
  "Intermediate or Adverse" = "#FEE08B",
  "Favorable or Intermediate" = "#D9EF8B",
  "Favorable" = "#91CF60",             
  "Unknown" = "#999999"                
)
ggplot(variaveis_pb_norm, aes(x = ELN_2017, y = Z_score, fill = ELN_2017)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.85, width = 0.7, color = "gray30") +
  facet_wrap(~ Celula, scales = "fixed", ncol = 4) +
  scale_fill_manual(values = paleta_eln, name = "Classificação ELN 2017") +
  coord_cartesian(ylim = c(-3, 3)) +
  theme_minimal(base_size = 12) +
  labs(
    title = "Distribuição Normalizada das Células do Sangue por Grupo ELN 2017",
    subtitle = "Valores padronizados (z-score) por tipo de célula",
    x = "Classificação ELN 2017", y = "Z-score"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.y = element_line(color = "gray85", linetype = "dashed"),
    strip.text = element_text(face = "bold", size = 11),
    legend.position = "bottom",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10)
  ) +
  guides(fill = guide_legend(nrow = 2, byrow = TRUE))
```

## 2.9. Análise de Componentes Principais (PCA) para caracterizar as Células Sanguíneas no contexto da Classificação ELN 2017

### 2.9.1. Seleção e normalização

```{r}
dados_celulas_pb_scaled <- dc_amostras %>%
  select(ELN_2017, PB_BASOPHILS_PERCENTAGE, PB_BLAST_PERCENTAGE, PB_EOSINOPHILS_PERCENTAGE,
         PB_IMMATURE_GRANULOCYTES_PERCENTAGE, PB_LYMPHOCYTES_PERCENTAGE,
         PB_MONOCYTES_PERCENTAGE, PB_NEUTROPHILS_PERCENTAGE, PB_NUCLEATED_RBC_PERCENTAGE) %>%
  filter(!is.na(ELN_2017)) %>%
  drop_na()

matriz_numeric <- dados_celulas_pb_scaled %>%
  select(-ELN_2017) %>%
  scale()
```

### 2.9.1. Resultado do PCA

```{r}
pca_result <- prcomp(matriz_numeric, center = TRUE, scale. = TRUE)
pca_result

pca_data <- as.data.frame(pca_result$x)
pca_data$ELN_2017 <- dados_celulas_pb_scaled$ELN_2017

pca_data <- as.data.frame(pca_result$x)
pca_data$ELN_2017 <- dc_amostras$ELN_2017[!is.na(dc_amostras$PB_BASOPHILS_PERCENTAGE) & 
                                            !is.na(dc_amostras$PB_BLAST_PERCENTAGE) & 
                                            !is.na(dc_amostras$PB_EOSINOPHILS_PERCENTAGE) & 
                                            !is.na(dc_amostras$PB_IMMATURE_GRANULOCYTES_PERCENTAGE) & 
                                            !is.na(dc_amostras$PB_LYMPHOCYTES_PERCENTAGE) & 
                                            !is.na(dc_amostras$PB_MONOCYTES_PERCENTAGE) & 
                                            !is.na(dc_amostras$PB_NEUTROPHILS_PERCENTAGE) & 
                                            !is.na(dc_amostras$PB_NUCLEATED_RBC_PERCENTAGE)]
```

### 2.9.2. Gráfico de dispersão entre PC1 e PC2

```{r}
ggplot(pca_data, aes(x = PC1, y = PC2, color = ELN_2017)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_manual(values = c("Adverse" = "#D55E00", "Favorable" = "#009E73", 
                                "Favorable or Intermediate" = "#56B4E9", 
                                "Intermediate" = "#F0E442", 
                                "Intermediate or Adverse" = "#CC79A7", 
                                "Unknown" = "#999999")) +
  labs(title = "Distribuição dos Pacientes nos Componentes Principais (PCA)", 
       x = "PC1", y = "PC2", color = "Classificação ELN 2017") +
  theme_minimal() +
  theme(legend.position = "right")
```

### 2.9.3. Gráfico de dispersão entre PC1 e PC3

```{r}
ggplot(pca_data, aes(x = PC1, y = PC3, color = ELN_2017)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_manual(values = c("Adverse" = "#D55E00", "Favorable" = "#009E73", 
                                "Favorable or Intermediate" = "#56B4E9", 
                                "Intermediate" = "#F0E442", 
                                "Intermediate or Adverse" = "#CC79A7", 
                                "Unknown" = "#999999")) +
  labs(title = "Distribuição dos Pacientes nos Componentes Principais (PC1 vs PC3)",
       x = "PC1", y = "PC3", color = "Classificação ELN 2017") +
  theme_minimal() +
  theme(legend.position = "right")
```

### 2.9.4. Gráfico de barras para a proporção da variância explicada

```{r}
variancia <- summary(pca_result)$importance[2, ]
variancia_df <- data.frame(Component = paste0("PC", 1:length(variancia)), Variance_Proportion = variancia)

ggplot(variancia_df, aes(x = Component, y = Variance_Proportion)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Proporção da Variância Explicada por Cada Componente Principal",
       x = "Componente Principal", y = "Proporção da Variância Explicada") +
  theme_minimal()
```

# 3. Tratamento dos dados para realização de CLustering e Machine Learning

## 3.0. Instalação de packages

```{r}
install.packages("glmnet")
```

## 3.1. Pacotes Utilizados

```{r}
# Carregar pacotes necessários
library(dplyr)
library(glmnet)
library(tidyverse)
library(caret)
library(randomForest)
library(pROC)
library(Rtsne)
library(cluster)
library(e1071)  # Para SVM
library(nnet)  # Para Redes Neurais
library(MASS)  # para stepAIC
```

## 3.2. Filtragem das linhas com status conhecido
```{r}
# Filtrar dados clínicos para manter apenas as linhas com status conhecido (vivo ou falecido)
pacientes <- dc_pacientes %>%
  filter(OS_STATUS %in% c("1:DECEASED", "0:LIVING")) %>%
  mutate(STATUS_BIN = ifelse(OS_STATUS == "1:DECEASED", 1, 0))

head(pacientes)
```

## 3.3. Tratamento de dados Pacientes e Amostras
```{r}
# Escolher colunas com <30% NAs e variância > 1
pacientes <- pacientes %>%
  filter(OS_STATUS %in% c("1:DECEASED", "0:LIVING")) %>%
  mutate(STATUS_BIN = ifelse(OS_STATUS == "1:DECEASED", 1, 0)) %>%
  dplyr::select(PATIENT_ID, STATUS_BIN, everything()) %>% # obriga a utilizar o dplyr, caso contrário gera conflito
  dplyr::select(
    PATIENT_ID,
    STATUS_BIN,
    where(~mean(is.na(.)) < 0.3),
    where(~length(unique(na.omit(.))) > 1)
  )

amostras <- dc_amostras %>%
  dplyr::select(PATIENT_ID, everything()) %>% # obriga a utilizar o dplyr, caso contrário gera conflito
  dplyr::select(
    PATIENT_ID,
    where(~mean(is.na(.)) < 0.3),
    where(~length(unique(na.omit(.))) > 1)
  )

# Manter apenas uma amostra por paciente
amostras_unique <- amostras %>%
  group_by(PATIENT_ID) %>%
  slice(1) %>%
  ungroup()
```

## 3.4. Filtragem por pacientes em comum
```{r}
dados <- inner_join(amostras_unique, pacientes, by = "PATIENT_ID")
```

## 3.5. Limpeza dos Dados
```{r}
# Remover colunas com variância zero
dados <- dados[, sapply(dados, function(x) length(unique(x)) > 1)]

# Remover linhas com NAs
dados <- na.omit(dados)

# Converte para fator 
dados <- dados %>% mutate(across(where(is.character), as.factor))

colunas_protegidas <- c("PATIENT_ID", "SAMPLE_ID")

# Remover colunas com fenómenos raros
colunas_a_remover <- sapply(names(dados), function(nome_coluna) {
  col <- dados[[nome_coluna]]
  if (is.factor(col) && !(nome_coluna %in% colunas_protegidas)) {
    any(table(col) < 10)
  } else {
    FALSE
  }
})

# Mostrar colunas com menos de 10 casos

print(names(colunas_a_remover[colunas_a_remover]))

dados <- dados[, !colunas_a_remover]
```

## 3.6. Divisão dos dados em conjunto de treino e teste
```{r}
set.seed(123)
idx <- sample(nrow(dados), 0.8 * nrow(dados))
dados_treino <- dados[idx, ]
dados_teste  <- dados[-idx, ]
```

## 3.7. Sincronização de fatores
```{r}
# Remover colunas fator com apenas 1 nível no treino
fatores_invalidos <- sapply(dados_treino, function(col) {
  is.factor(col) && length(unique(col[!is.na(col)])) < 2
})
dados_treino <- dados_treino[, !fatores_invalidos]
dados_teste  <- dados_teste[, names(dados_treino)]

#Sincronizar níveis dos fatores entre treino e teste
for (col in names(dados_treino)) {
  if (is.factor(dados_treino[[col]])) {
    lvls <- union(levels(dados_treino[[col]]), levels(dados_teste[[col]]))
    dados_treino[[col]] <- factor(dados_treino[[col]], levels = lvls)
    dados_teste[[col]]  <- factor(dados_teste[[col]], levels = lvls)
  }
}
```

# 4. Modelação Preditiva

## 4.1. Regressão Logística

### 4.1.1. Preparação dos dados

```{r}
# Remover colunas que não devem ser usadas como preditoras no modelo:
# - Identificadores únicos (PATIENT_ID, SAMPLE_ID)
# - Variáveis relacionadas com o desfecho (OS_STATUS, OS_MONTHS) para evitar fuga de informação

dados_treino_model <- dados_treino %>%
  dplyr::select(-PATIENT_ID, -SAMPLE_ID, -OS_STATUS, -OS_MONTHS)

dados_teste_model <- dados_teste %>%
  dplyr::select(-PATIENT_ID, -SAMPLE_ID, -OS_STATUS, -OS_MONTHS)
```

### 4.1.2. Regressão logística com regularização (LASSO)

A regressão LASSO permite selecionar automaticamente as variáveis mais relevantes através da penalização L1, reduzindo o risco de sobreajuste. Foi utilizada validação cruzada para escolher o valor ótimo de lambda.

```{r}
# Criar matrizes de preditores (x) e vetor de resposta (y) para treino e teste
# model.matrix transforma variáveis categóricas em dummies (one-hot encoding)
x_treino <- model.matrix(STATUS_BIN ~ ., data = dados_treino_model)[, -1]
y_treino <- dados_treino_model$STATUS_BIN

x_teste  <- model.matrix(STATUS_BIN ~ ., data = dados_teste_model)[, -1]
y_teste  <- dados_teste_model$STATUS_BIN

# Confirmar que treino e teste têm o mesmo número de colunas
stopifnot(ncol(x_treino) == ncol(x_teste))

# Ajustar modelo LASSO com validação cruzada para escolher o melhor valor de lambda
set.seed(123)
cv_lasso <- cv.glmnet(x_treino, y_treino, family = "binomial", alpha = 1, type.measure = "class")
best_lambda <- cv_lasso$lambda.min  # Valor de lambda que minimiza o erro de classificação

# Prever probabilidades no conjunto de teste
pred_prob <- predict(cv_lasso, newx = x_teste, s = best_lambda, type = "response")

# Converter probabilidades em classes (limiar 0.5)
pred_class <- ifelse(pred_prob >= 0.5, 1, 0)

# Avaliação do desempenho
matriz_confusao <- table(Previsão = pred_class, Real = y_teste)
accuracy <- mean(pred_class == y_teste)

# Calcular a curva ROC para o modelo LASSO
roc_lasso <- roc(y_teste, pred_prob)

# Calcular a AUC para o modelo LASSO
auc_lasso <- auc(roc_lasso)


# Mostrar resultados
print(matriz_confusao)
print(paste("Precisão:", round(accuracy, 4)))
cat("\nRegressao Logistica LASSO AUC:", round(auc_lasso, 4), "\n") # Imprimir a AUC do LASSO
print(coef(cv_lasso, s = best_lambda))  # Coeficientes das variáveis selecionadas
plot(cv_lasso)  # Curva de validação cruzada
```

### 4.1.3. Análise univariada com AUC para seleção inicial

Foi realizada regressão logística simples para cada variável candidata. A escolha baseou-se na AUC (Área sob a Curva ROC), permitindo identificar as mais promissoras.

```{r}
# Lista de variáveis candidatas à modelação univariada
variaveis <- c("CUMULATIVE_TREATMENT_REGIMEN_COUNT", 
               "AGE_AT_PROCUREMENT", 
               "SOMATIC_STATUS", 
               "MDS_TWO_MONTHS_PRIOR_AML")

# Inicializar vetor de resultados
resultados_auc <- c()

# Loop de modelagem univariada
for (var in variaveis) {
  
  # Verifica se a variável existe nas duas bases
  if (!(var %in% names(dados_treino)) || !(var %in% names(dados_teste))) {
    warning(paste("Variável não encontrada:", var))
    next
  }
  
  # Ajusta modelo
  formula_str <- as.formula(paste("STATUS_BIN ~", var))
  modelo <- glm(formula_str, data = dados_treino, family = "binomial")
  
  # Previsão e cálculo do AUC
  prob <- predict(modelo, newdata = dados_teste, type = "response")
  roc_obj <- roc(dados_teste$STATUS_BIN, prob)
  resultados_auc[var] <- auc(roc_obj)
}

# Mostrar os AUCs ordenados
print(sort(resultados_auc, decreasing = TRUE))

```

### 4.1.4. Modelo Simples com AGE\_AT\_PROCUREMENT**

A variável "AGE_AT_PROCUREMENT" destacou-se pela sua significância e desempenho preditivo.

```{r}
# Ajustar modelo com uma única variável (idade)
modelo_idade <- glm(STATUS_BIN ~ AGE_AT_PROCUREMENT, data = dados_treino, family = "binomial")

# Resumo do modelo com coeficientes, erro padrão e p-valores
summary(modelo_idade)

# Previsões no conjunto de teste
prob_idade <- predict(modelo_idade, newdata = dados_teste, type = "response")
classe_pred <- ifelse(prob_idade >= 0.5, 1, 0)

# Avaliação
matriz_confusao <- table(Predito = classe_pred, Real = dados_teste$STATUS_BIN)
accuracy_simp <- mean(classe_pred == dados_teste$STATUS_BIN)

print(matriz_confusao)
print(paste("Precisão:", round(accuracy_simp, 4)))

# Curva ROC e AUC
roc_idade <- roc(dados_teste$STATUS_BIN, prob_idade)
plot(roc_idade, main = "Curva ROC - AGE_AT_PROCUREMENT", col = "blue", lwd = 2)
auc_valor <- auc(roc_idade)
print(paste("AUC:", round(auc_valor, 4)))
```

### 4.1.5. Discussão do modelo multivariado

As variáveis incluídas no modelo de regressão logística multivariada foram selecionadas com base na sua relevância estatística e clínica. A variável **AGE\_AT\_PROCUREMENT**, que representa a idade do paciente no momento da colheita, revelou-se estatisticamente significativa no modelo multivariado, com um coeficiente positivo e um valor de p inferior a 0.001. Do ponto de vista clínico, a idade é amplamente reconhecida como um fator prognóstico importante em doentes com Leucemia Mieloide Aguda (LMA). Pacientes mais idosos tendem a ter menor tolerância a tratamentos intensivos e a apresentar piores desfechos clínicos, o que justifica plenamente a inclusão desta variável no modelo.


Por fim, a variável **CUMULATIVE\_TREATMENT\_REGIMEN\_COUNT**, que corresponde ao número acumulado de esquemas terapêuticos administrados ao paciente, demonstrou um coeficiente positivo estatisticamente significativo (valor de p aproximado de 0.0026), tanto no modelo multivariado como na seleção por stepwise. Este número reflete indiretamente a complexidade do tratamento e a gravidade do caso, sugerindo resistência terapêutica, doença refratária ou recorrente, ou ainda uma maior toxicidade acumulada. Todos estes fatores estão associados a um pior prognóstico em doentes com LMA.

Em conjunto, estas três variáveis foram selecionadas por apresentarem uma combinação equilibrada entre capacidade discriminativa, significância estatística e coerência com o conhecimento clínico atual sobre a evolução e tratamento da LMA. A sua inclusão contribui para tornar o modelo mais robusto, informativo e clinicamente interpretável.


### 4.1.6. Regressão logística multivariada (sem penalização)

Modelo com as três variáveis selecionadas: idade, presença de MDS nos 2 meses anteriores, e número cumulativo de regimes de tratamento.

```{r}
# Ajustar modelo com duas variáveis preditoras selecionadas pela AUC
modelo_multi <- glm(STATUS_BIN ~ AGE_AT_PROCUREMENT + 
                    CUMULATIVE_TREATMENT_REGIMEN_COUNT, 
                    data = dados_treino, family = "binomial")

# Resumo com significância estatística dos coeficientes
summary(modelo_multi)

# Previsão no teste
prob_multi <- predict(modelo_multi, newdata = dados_teste, type = "response")
classe_predita_multi <- ifelse(prob_multi >= 0.5, 1, 0)

# Avaliação
matriz_confusao_multi <- table(Predito = classe_predita_multi, Real = dados_teste$STATUS_BIN)
precisao_multi <- mean(classe_predita_multi == dados_teste$STATUS_BIN)

print(matriz_confusao_multi)
print(paste("Precisão:", round(precisao_multi, 4)))

# Curva ROC
roc_multi <- roc(dados_teste$STATUS_BIN, prob_multi)
plot(roc_multi, main = "Curva ROC - Modelo Multivariado", col = "darkgreen", lwd = 2)
auc_multi <- auc(roc_multi)
print(paste("AUC:", round(auc_multi, 4)))
```

### 4.1.6. Modelo com seleção stepwise

A seleção stepwise (critério AIC) foi utilizada para confirmar se algum termo deveria ser removido do modelo multivariado.

```{r}
# Modelo inicial com todas as variáveis candidatas
modelo_full <- glm(STATUS_BIN ~ AGE_AT_PROCUREMENT + 
                   CUMULATIVE_TREATMENT_REGIMEN_COUNT, 
                   data = dados_treino, family = "binomial")

# Aplicar stepwise bidirecional com base no critério AIC
modelo_step <- stepAIC(modelo_full, direction = "both", trace = FALSE)

# Resumo do modelo final selecionado
summary(modelo_step)

# Previsões
prob_step <- predict(modelo_step, newdata = dados_teste, type = "response")
classe_predita_step <- ifelse(prob_step >= 0.5, 1, 0)

# Avaliação
matriz_confusao_step <- table(Predito = classe_predita_step, Real = dados_teste$STATUS_BIN)
acuracy_step <- mean(classe_predita_step == dados_teste$STATUS_BIN)

print(matriz_confusao_step)
print(paste("Precisão:", round(acuracy_step, 4)))

# Curva ROC
roc_step <- roc(dados_teste$STATUS_BIN, prob_step)
plot(roc_step, main = "Curva ROC - Modelo Stepwise", col = "purple", lwd = 2)
auc_step <- auc(roc_step)
print(paste("AUC:", round(auc_step, 4)))
```

### 4.1.7. Comparação final dos modelos de regressão

```{r}
# Criar um data.frame para comparação clara entre os modelos testados

roc_lasso <- roc(y_teste, as.vector(pred_prob))
auc_lasso <- auc(roc_lasso)


resumo_modelos <- data.frame(
  Modelo   = c("LASSO", "Simples (Idade)", "Multivariado", "Stepwise"),
  Precisão = c(accuracy, accuracy_simp, precisao_multi, acuracy_step),
  AUC      = c(auc_lasso, auc_valor, auc_multi, auc_step)
)

# Mostrar resultados finais
print(resumo_modelos)
```

## 4.2. Modelo 2: Random Forest

### 4.2.1. Funções auxiliares para pré-processamento
```{r}
# Função para remover níveis dos factores no conjunto de teste
# que não existem no conjunto de treino
remove_niveis_novos <- function(train_df, test_df) {
  fact_cols <- names(train_df)[sapply(train_df, is.factor)]
  
  for (col in fact_cols) {
    niveis_validos <- levels(train_df[[col]])
    linhas_invalidas <- !(test_df[[col]] %in% niveis_validos)
    
    cat(paste0("Coluna '", col, "' tem ", sum(linhas_invalidas), " linhas com níveis inválidos.\n"))
    
    test_df[[col]][linhas_invalidas] <- NA
  }
  
  test_df_limpo <- test_df %>% na.omit()
  return(test_df_limpo)
}

# Função para alinhar os níveis dos factores entre treino e teste

alinhar_niveis <- function(treino, teste) {
  for (col in names(treino)) {
    if (is.factor(treino[[col]]) && col %in% names(teste)) {
      niveis_treino <- levels(treino[[col]])
      teste[[col]] <- factor(teste[[col]], levels = niveis_treino)
}

}

return(teste)

}
```


### 4.2.2. Treino do modelo
```{r}
# Preparar dados de treino para Random Forest obrigando à utilização do dplyr
dados_treino_rf <- dados_treino %>%
  dplyr::select(-PATIENT_ID, -SAMPLE_ID, -OS_STATUS, -OS_MONTHS) %>%
  dplyr::mutate(STATUS_BIN = factor(STATUS_BIN, levels = c(0, 1))) %>%
  dplyr::mutate(across(where(is.character), as.factor)) %>%
  dplyr::mutate(across(where(is.factor), droplevels))

# Criar modelo Random Forest com validação cruzada (5-fold)
set.seed(123)
rf_model <- train(
  STATUS_BIN ~ ., 
  data = dados_treino_rf,
  method = "rf",
  importance = TRUE,
  trControl = trainControl(method = "cv", number = 5)
)

# Avaliar importância das variáveis no modelo Random Forest
rf_importance <- varImp(rf_model, scale = FALSE)

# Calcular a média da importância entre as classes 0 e 1 para cada variável
important_vars_rf <- rf_importance$importance %>%
  mutate(Media = rowMeans(across(c("0", "1")))) %>%
  arrange(desc(Media))

# Visualizar tabela ordenada das variáveis mais importantes
print(important_vars_rf)

# Gráfico das 20 variáveis mais importantes (com base na média das importâncias)
top_vars <- head(important_vars_rf, 20)
barplot(
  top_vars$Media,
  names.arg = rownames(top_vars),
  las = 2,
  col = "steelblue",
  main = "Top 20 variáveis importantes - Random Forest",
  cex.names = 0.7
)
```


### 4.2.3. Preparação dos dados de teste
```{r}

# Preparar dados de teste para Random Forest forçando o uso do dplyr
dados_teste_rf <- dados_teste %>%
  dplyr::select(-PATIENT_ID, -SAMPLE_ID, -OS_STATUS, -OS_MONTHS) %>%
  dplyr::mutate(STATUS_BIN = factor(STATUS_BIN, levels = c(0, 1))) %>%
  dplyr::mutate(across(where(is.character), as.factor)) %>%
  dplyr::mutate(across(where(is.factor), droplevels))

# Alinhar níveis dos fatores entre treino e teste
dados_teste_rf <- alinhar_niveis(dados_treino_rf, dados_teste_rf)

# Separar a variável resposta antes da limpeza
resposta_teste <- dados_teste_rf$STATUS_BIN

# Remover níveis novos nos preditores do teste 
dados_teste_rf_clean <- remove_niveis_novos(
  dplyr::select(dados_treino_rf, -STATUS_BIN),
  dplyr::select(dados_teste_rf, -STATUS_BIN)
)

# Os índices numéricos das rownames garantem que associamos corretamente cada valor de STATUS_BIN às linhas restantes após a limpeza

dados_teste_rf <- dados_teste_rf_clean %>%
  mutate(STATUS_BIN = resposta_teste[as.numeric(rownames(dados_teste_rf_clean))])
```



### 4.2.4. Avaliação de Desempenho do Modelo
#### 4.2.4.1. Matriz de Confusão
```{r}
# Prever classes com o modelo Random Forest
previsoes <- predict(rf_model, newdata = dados_teste_rf)

# Garantir que ambas as variáveis estão como factor com os mesmos níveis
previsoes <- factor(previsoes, levels = c(0, 1))
dados_teste_rf$STATUS_BIN <- factor(dados_teste_rf$STATUS_BIN, levels = c(0, 1))

# Avaliar o desempenho do modelo Random Forest no conjunto de teste
confusionMatrix(previsoes, dados_teste_rf$STATUS_BIN, positive = "1")
```


#### 4.2.4.2. Curva ROC e AUC - Random Forest
```{r}
# Prever probabilidades da classe positiva (STATUS_BIN = 1, assumindo que representa "DECEASED")
rf_probs <- predict(rf_model, newdata = dados_teste_rf, type = "prob")[, "1"]

# Calcular a curva ROC
rf_roc <- roc(dados_teste_rf$STATUS_BIN, rf_probs)

# Calcular a AUC
rf_auc <- auc(rf_roc)

# Imprimir a AUC
cat("\nRandom Forest AUC:", round(rf_auc, 4), "\n")

# Plot da curva ROC do Random Forest
plot(rf_roc, col = "red", lwd = 2, main = "Curva ROC - Random Forest")
```


## 4.3. Modelo 3: SVM

### 4.3.1. Preparação dos dados para SVM
```{r}
# Preparar dados de treino para SVM forçando dplyr
dados_treino_svm <- dados_treino %>%
  dplyr::select(-PATIENT_ID, -SAMPLE_ID, -OS_STATUS, -OS_MONTHS) %>%
  dplyr::mutate(STATUS_BIN = factor(STATUS_BIN))

# Preparar dados de teste para SVM (mantendo as mesmas colunas do treino)
dados_teste_svm <- dados_teste %>%
  dplyr::select(dplyr::any_of(names(dados_treino_svm))) %>% # Seleciona apenas colunas presentes no treino
  dplyr::mutate(STATUS_BIN = factor(STATUS_BIN, levels = levels(dados_treino_svm$STATUS_BIN)))
```


### 4.3.2. Treino do modelo SVM (Kernel Linear)
```{r}
# Treinar modelo SVM com kernel linear
set.seed(123)
svm_model_linear <- svm(STATUS_BIN ~ .,
                         data = dados_treino_svm,
                         kernel = "linear",
                         probability = TRUE) # Ativa o cálculo de probabilidades
```

### 4.3.3. Previsões com modelo SVM (Kernel Linear)
```{r}
# Fazer previsões de classe no conjunto de teste
previsoes_svm_classe <- predict(svm_model_linear, newdata = dados_teste_svm)

# Fazer previsões de probabilidade no conjunto de teste
previsoes_svm_prob <- predict(svm_model_linear, newdata = dados_teste_svm, probability = TRUE)
prob_svm <- attr(previsoes_svm_prob, "probabilities")[, "1"] # Probabilidade da classe '1' (DECEASED)

```

### 4.3.4. Avaliação do desempenho do modelo SVM (Kernel Linear)
```{r}
# Matriz de Confusão
matriz_confusao_svm <- table(Previsto = previsoes_svm_classe, Real = dados_teste_svm$STATUS_BIN)
print("Matriz de Confusão (SVM Linear):")
print(matriz_confusao_svm)

# Precisão
precisao_svm <- mean(previsoes_svm_classe == dados_teste_svm$STATUS_BIN)
print(paste("Precisão (SVM Linear):", round(precisao_svm, 4)))

# Curva ROC e AUC
roc_svm <- roc(dados_teste_svm$STATUS_BIN, prob_svm)
auc_svm <- auc(roc_svm)
cat("\nSVM Linear AUC:", round(auc_svm, 4), "\n")

# Plot da curva ROC do SVM Linear
plot(roc_svm, col = "purple", lwd = 2, main = "Curva ROC - SVM (Kernel Linear)")
```

# 5. Clustering de Amostras
```{r}
# Remover colunas de ID
dados_sem_id <- dados %>%
  dplyr::select(-PATIENT_ID, -SAMPLE_ID)

# Selecionar apenas as colunas numéricas para o clustering
dados_numerico <- dados_sem_id %>%
  select_if(is.numeric)

# Remover linhas com quaisquer valores ausentes nas colunas numéricas selecionadas
dados_clustering <- na.omit(dados_numerico)

# Escalar os dados
dados_clustering_scaled <- scale(dados_clustering)

# Calcular a matriz de distância Euclidiana
distancia_samples <- dist(dados_clustering_scaled, method = "euclidean")

# Realizar o clustering hierárquico usando o método "complete linkage"
cluster_samples <- hclust(distancia_samples, method = "complete")

# Visualizar o dendrograma de amostras
plot(cluster_samples, main = "Dendrograma de Clustering de Amostras")
```

# 6. Redução de Dimensionalidade

## 6.1. PCA

```{r}
# Selecionar apenas as colunas numéricas relevantes para PCA
dados_pca <- dados %>%
  dplyr::select_if(is.numeric) %>%
  dplyr::select(-STATUS_BIN) %>%
  dplyr::select(where(~ sd(.) > 0))

# Remover linhas com valores ausentes
dados_pca_clean <- na.omit(dados_pca)

pca_res <- prcomp(dados_pca_clean, scale. = TRUE)
summary(pca_res)

# Visualizaão grafica de PCA (2 primeiros componentes principais)
pca_data <- as.data.frame(pca_res$x)
ggplot(pca_data, aes(PC1, PC2)) +
  geom_point(aes(color = dados$OS_STATUS)) + # Usar 'dados$OS_STATUS' para colorir
  ggtitle("PCA - Analise de Componentes Principais")
```

## 6.2. t-SNE
```{r}
# t-SNE para redução de dimensionalidade
# Selecionar apenas as colunas numéricas relevantes para t-SNE
dados_tsne <- dados %>%
  dplyr::select_if(is.numeric) %>%
  dplyr::select(-STATUS_BIN) 

# Remover linhas com valores ausentes 
dados_tsne_clean <- na.omit(dados_tsne)

tsne_res <- Rtsne(dados_tsne_clean, dims = 2, perplexity = 14, verbose = TRUE, max_iter = 500)
tsne_data <- as.data.frame(tsne_res$Y)
ggplot(tsne_data, aes(V1, V2)) +
  geom_point(aes(color = dados$OS_STATUS)) + # Usar 'dados$OS_STATUS' para colorir
  ggtitle("t-SNE - Reducao de Dimensionalidade")
```


## 6.3. MDS
```{r}
# Selecionar apenas as colunas numéricas relevantes para calcular a dissimilaridade
dados_mds <- dados %>%
  dplyr::select_if(is.numeric) %>%
  dplyr::select(-STATUS_BIN) 

# Remover linhas com valores ausentes
dados_mds_clean <- na.omit(dados_mds)

# Calcular a matriz de dissimilaridade (usando distância Euclidiana nos dados escalados)
dist_mds <- dist(scale(dados_mds_clean), method = "euclidean")

mds_res <- cmdscale(dist_mds, k = 2)
mds_data <- as.data.frame(mds_res)
colnames(mds_data) <- c("V1", "V2")
ggplot(mds_data, aes(V1, V2)) +
  geom_point(aes(color = dados$OS_STATUS)) + # Usar 'dados$OS_STATUS' para colorir
  ggtitle("MDS - Escalonamento Multidimensional")
```

# 7. Discussão

A análise preditiva para o status vital dos pacientes foi realizada utilizando regressão logística e Random Forest, com base em variáveis clínicas como idade, sexo e etnia. A regressão logística apresentou um desempenho ligeiramente superior (AUC ≈ 0.73), enquanto o Random Forest obteve uma AUC ligeiramente inferior (≈ 0.69). Esse desempenho da regressão logística pode estar relacionado à simplicidade dos dados e à ausência de interações complexas entre as variáveis, favorecendo modelos lineares.

Por outro lado, ao utilizar os dados moleculares das amostras, o modelo Random Forest mostrou-se mais robusto, possivelmente por conseguir capturar interações mais complexas entre variáveis de alta dimensionalidade.

As técnicas de redução de dimensionalidade como PCA, t-SNE e MDS permitiram explorar visualmente a estrutura dos dados, revelando padrões de agrupamento entre as amostras com características clínicas ou moleculares semelhantes. No entanto, não foi realizada uma análise formal de clustering, como k-means ou agrupamento hierárquico.

No geral, os resultados sugerem que diferentes fontes de dados (clínicos vs. moleculares) exigem abordagens distintas para modelagem preditiva, e que a complexidade dos dados deve guiar a escolha do modelo.


# 8. Bibliografia
